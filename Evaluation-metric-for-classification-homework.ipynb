{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "82ce648e",
   "metadata": {},
   "source": [
    "### Homework"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad0e7c87",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "\n",
    "In this homework, we will use Credit Card Data from book \"Econometric Analysis\".\n",
    "\n",
    "Here's a wget-able link:\n",
    "\n",
    "wget https://raw.githubusercontent.com/alexeygrigorev/datasets/master/AER_credit_card_data.csv\n",
    "The goal of this homework is to inspect the output of different evaluation metrics by creating a classification model (target column card)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b676f360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import random\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "pd.set_option('display.max_rows', None)\n",
    "pd.set_option('display.max_columns', None)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fce37a0",
   "metadata": {},
   "source": [
    "### Preparation\n",
    "\n",
    "- Create the target variable by mapping yes to 1 and no to 0.\n",
    "- Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "df4b75e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1319\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('/Users/admin/Documents/Data Science/ml-zoomcamp/Module 4 Evaluation Metrics for Classification/AER_credit_card_data.csv')\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b4e90cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the target variable by mapping yes to 1 and no to 0.\n",
    "df['card'] = (df['card'] == 'yes').astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c90c322",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>card</th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>37.66667</td>\n",
       "      <td>4.5200</td>\n",
       "      <td>0.033270</td>\n",
       "      <td>124.983300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.25000</td>\n",
       "      <td>2.4200</td>\n",
       "      <td>0.005217</td>\n",
       "      <td>9.854167</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>33.66667</td>\n",
       "      <td>4.5000</td>\n",
       "      <td>0.004156</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>4</td>\n",
       "      <td>58</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>30.50000</td>\n",
       "      <td>2.5400</td>\n",
       "      <td>0.065214</td>\n",
       "      <td>137.869200</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>32.16667</td>\n",
       "      <td>9.7867</td>\n",
       "      <td>0.067051</td>\n",
       "      <td>546.503300</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   card  reports       age  income     share  expenditure owner selfemp  \\\n",
       "0     1        0  37.66667  4.5200  0.033270   124.983300   yes      no   \n",
       "1     1        0  33.25000  2.4200  0.005217     9.854167    no      no   \n",
       "2     1        0  33.66667  4.5000  0.004156    15.000000   yes      no   \n",
       "3     1        0  30.50000  2.5400  0.065214   137.869200    no      no   \n",
       "4     1        0  32.16667  9.7867  0.067051   546.503300   yes      no   \n",
       "\n",
       "   dependents  months  majorcards  active  \n",
       "0           3      54           1      12  \n",
       "1           3      34           1      13  \n",
       "2           4      58           1       5  \n",
       "3           0      25           1       7  \n",
       "4           2      64           1       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c317fcee",
   "metadata": {},
   "source": [
    "### Split the dataset into 3 parts: train/validation/test with 60%/20%/20% distribution. Use train_test_split funciton for that with random_state=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35db886c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_full_train, df_test = train_test_split(df, test_size=0.2, random_state=1)\n",
    "df_train, df_val = train_test_split(df_full_train, test_size=0.25, random_state=1)\n",
    "\n",
    "df_train = df_train.reset_index(drop=True)\n",
    "df_val = df_val.reset_index(drop=True)\n",
    "df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "y_train = df_train.card.values\n",
    "y_val = df_val.card.values\n",
    "y_test = df_test.card.values\n",
    "\n",
    "del df_train['card']\n",
    "del df_val['card']\n",
    "del df_test['card']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c15f9759",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791, 264, 264)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train), len(df_val), len(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9414bc82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791, 264, 264)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_train), len(y_val), len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c5efddf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of numerical variables\n",
    "numerical = [col for col in df.columns if df[col].dtypes != 'object']\n",
    "categorical = [col for col in df.columns if df[col].dtypes == 'object']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f915da8",
   "metadata": {},
   "source": [
    "# Question 1\n",
    "\n",
    "ROC AUC could also be used to evaluate feature importance of numerical variables.\n",
    "\n",
    "Let's do that\n",
    "\n",
    "- For each numerical variable, use it as score and compute AUC with the card variable.\n",
    "- Use the training dataset for that.\n",
    "\n",
    "If your AUC is < 0.5, invert this variable by putting \"-\" in front\n",
    "\n",
    "(e.g. -df_train['expenditure'])\n",
    "\n",
    "AUC can go below 0.5 if the variable is negatively correlated with the target varialble. You can change the direction of the correlation by negating this variable - then negative correlation becomes positive.\n",
    "\n",
    "Which numerical variable (among the following 4) has the highest AUC?\n",
    "\n",
    "- reports\n",
    "- dependents\n",
    "- active\n",
    "- share"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2eecc67a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['card',\n",
       " 'reports',\n",
       " 'age',\n",
       " 'income',\n",
       " 'share',\n",
       " 'expenditure',\n",
       " 'dependents',\n",
       " 'months',\n",
       " 'majorcards',\n",
       " 'active']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec90d50d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "card : 1.0\n",
      "reports : 0.28219862090829834\n",
      "age : 0.4986245409632507\n",
      "income : 0.5888896594541755\n",
      "share : 0.9898054212570342\n",
      "expenditure : 0.9897360703812317\n",
      "dependents : 0.4742278935827323\n",
      "months : 0.48211738131092974\n",
      "majorcards : 0.5499111648305197\n",
      "active : 0.5824680985971309\n"
     ]
    }
   ],
   "source": [
    "for col in numerical:\n",
    "    auc_scores = roc_auc_score(df['card'], df[col])\n",
    "    print(col, ':', auc_scores)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1cc215e",
   "metadata": {},
   "source": [
    "Among four highlighted variables, share has the highest auc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9fe4027",
   "metadata": {},
   "source": [
    "# Training the model\n",
    "From now on, use these columns only:\n",
    "\n",
    "[\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]\n",
    "\n",
    "Apply one-hot-encoding using DictVectorizer and train the logistic regression with these parameters:\n",
    "\n",
    "LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "02394d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_columns = [\"reports\", \"age\", \"income\", \"share\", \"expenditure\", \"dependents\", \"months\", \"majorcards\", \"active\", \"owner\", \"selfemp\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0bdb6a02",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train_use = df_train[use_columns]\n",
    "df_val_use = df_val[use_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "102acdb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(791, 264)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_use), len(df_val_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "41b56ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reports</th>\n",
       "      <th>age</th>\n",
       "      <th>income</th>\n",
       "      <th>share</th>\n",
       "      <th>expenditure</th>\n",
       "      <th>dependents</th>\n",
       "      <th>months</th>\n",
       "      <th>majorcards</th>\n",
       "      <th>active</th>\n",
       "      <th>owner</th>\n",
       "      <th>selfemp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>40.50000</td>\n",
       "      <td>4.0128</td>\n",
       "      <td>0.000299</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>32.33333</td>\n",
       "      <td>6.0000</td>\n",
       "      <td>0.000200</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>4</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>29.16667</td>\n",
       "      <td>2.2000</td>\n",
       "      <td>0.038205</td>\n",
       "      <td>69.79333</td>\n",
       "      <td>0</td>\n",
       "      <td>49</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>54.66667</td>\n",
       "      <td>7.2900</td>\n",
       "      <td>0.106536</td>\n",
       "      <td>647.20670</td>\n",
       "      <td>2</td>\n",
       "      <td>78</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>25.00000</td>\n",
       "      <td>3.3984</td>\n",
       "      <td>0.000353</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>2</td>\n",
       "      <td>29</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   reports       age  income     share  expenditure  dependents  months  \\\n",
       "0        3  40.50000  4.0128  0.000299      0.00000           1      12   \n",
       "1        1  32.33333  6.0000  0.000200      0.00000           4      18   \n",
       "2        1  29.16667  2.2000  0.038205     69.79333           0      49   \n",
       "3        1  54.66667  7.2900  0.106536    647.20670           2      78   \n",
       "4        0  25.00000  3.3984  0.000353      0.00000           2      29   \n",
       "\n",
       "   majorcards  active owner selfemp  \n",
       "0           1      17    no      no  \n",
       "1           1       4   yes      no  \n",
       "2           1       7    no      no  \n",
       "3           1       9   yes      no  \n",
       "4           0       4   yes      no  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_use.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fdfecf59",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the DictVectorizer for ohe\n",
    "dv = DictVectorizer(sparse=False)\n",
    "\n",
    "# Train and fit DictVectorizer for both train and validation date subset\n",
    "train_dict = df_train_use.to_dict(orient='records')\n",
    "X_train = dv.fit_transform(train_dict)\n",
    "\n",
    "val_dict = df_val_use.to_dict(orient='records')\n",
    "X_val = dv.transform(val_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bcf10309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(max_iter=1000, solver='liblinear')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training the model\n",
    "model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "\n",
    "# Fit the model\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "32256812",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model prediction on validation dataset\n",
    "y_pred = model.predict_proba(X_val)[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9165e815",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "card_decision = (y_pred >= 0.5)\n",
    "(y_val == card_decision).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1572d302",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9696969696969697"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_val, y_pred >= 0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "efc4a303",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confusion matrix\n",
    "# actual churning and not churning\n",
    "actual_positive = (y_val == 1)\n",
    "actual_negative = (y_val == 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2ed05a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prediction\n",
    "t = 0.5\n",
    "predict_positive = (y_pred >= t)\n",
    "predict_negative = (y_pred < t)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b80705a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting true positive, true negative, false positive, false negative\n",
    "tp = (predict_positive & actual_positive).sum()\n",
    "tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "fp = (predict_positive & actual_negative).sum()\n",
    "fn = (predict_negative & actual_positive).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c466af0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp : 204\n",
      "tn : 52\n",
      "fp : 1\n",
      "fn : 52\n"
     ]
    }
   ],
   "source": [
    "print('tp :', tp)\n",
    "print('tn :', tn)\n",
    "print('fp :', fp)\n",
    "print('fn :', tn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0b27d676",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 52,   1],\n",
       "       [  7, 204]])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix = np.array([\n",
    "    [tn, fp],\n",
    "    [fn, tp]\n",
    "])\n",
    "confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f47ec6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9951219512195122"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Precision is the percentage or number of positive predictions that are correct or eventually positive (i.e. TP/(TP+FP))\n",
    "p = tp / (tp + fp)\n",
    "p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a5eba6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966824644549763"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# percentage of correctly identified positive examples\n",
    "r = tp / (tp + fn)\n",
    "r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ec2cf6f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.966824644549763"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TPR is the ratio of making a correct positive prediction to all positive outcome. The goal her is to maximize TPR\n",
    "tpr = tp / (tp + fn)\n",
    "tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "839d8bd4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.018867924528301886"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# FPR is the ratio of FP (i.e wrongly predicting negative as positive) to all the negative occurence. \n",
    "#The goal is to minimize FPR\n",
    "fpr = fp / (fp + tn)\n",
    "fpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c77dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c840586b",
   "metadata": {},
   "source": [
    "# Question 2\n",
    "\n",
    "What's the AUC of this model on the validation dataset? (round to 3 digits)\n",
    "\n",
    "- 0.615\n",
    "- 0.515\n",
    "- 0.715\n",
    "- 0.995"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c107b62a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.995"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculating area under the curve\n",
    "roc_auc_score(y_val, y_pred).round(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885418eb",
   "metadata": {},
   "source": [
    "# Question 3\n",
    "\n",
    "Now let's compute precision and recall for our model.\n",
    "\n",
    "Evaluate the model on all thresholds from 0.0 to 1.0 with step 0.01\n",
    "For each threshold, compute precision and recall\n",
    "Plot them\n",
    "At which threshold precision and recall curves intersect?\n",
    "\n",
    "- 0.1\n",
    "- 0.3\n",
    "- 0.6\n",
    "- 0.8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "403cfaed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.11, 0.12, 0.13, 0.14, 0.15, 0.16, 0.17, 0.18, 0.19, 0.2, 0.21, 0.22, 0.23, 0.24, 0.25, 0.26, 0.27, 0.28, 0.29, 0.3, 0.31, 0.32, 0.33, 0.34, 0.35, 0.36, 0.37, 0.38, 0.39, 0.4, 0.41, 0.42, 0.43, 0.44, 0.45, 0.46, 0.47, 0.48, 0.49, 0.5, 0.51, 0.52, 0.53, 0.54, 0.55, 0.56, 0.57, 0.58, 0.59, 0.6, 0.61, 0.62, 0.63, 0.64, 0.65, 0.66, 0.67, 0.68, 0.69, 0.7, 0.71, 0.72, 0.73, 0.74, 0.75, 0.76, 0.77, 0.78, 0.79, 0.8, 0.81, 0.82, 0.83, 0.84, 0.85, 0.86, 0.87, 0.88, 0.89, 0.9, 0.91, 0.92, 0.93, 0.94, 0.95, 0.96, 0.97, 0.98, 0.99]\n"
     ]
    }
   ],
   "source": [
    "import decimal\n",
    "\n",
    "def float_range(start, stop, step):\n",
    "  while start < stop:\n",
    "    yield float(start)\n",
    "    start += decimal.Decimal(step)\n",
    "\n",
    "print(list(float_range(0, 1, '0.01')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "281eb072",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting contents of confusion matrix as different threasholds\n",
    "scores = []\n",
    "\n",
    "thresholds = float_range(0, 1, '0.01')\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    \n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    \n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn, p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "23196445",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the scores into datafram\n",
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'p', 'r']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "26b5a3c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>211</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>211</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.861224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>211</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>211</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>211</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp  fp  fn  tn         p    r\n",
       "0       0.00  211  53   0   0  0.799242  1.0\n",
       "1       0.01  211  34   0  19  0.861224  1.0\n",
       "2       0.02  211  31   0  22  0.871901  1.0\n",
       "3       0.03  211  24   0  29  0.897872  1.0\n",
       "4       0.04  211  22   0  31  0.905579  1.0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3ec388c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce006c8940>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores.threshold, df_scores['p'], label='P')\n",
    "plt.plot(df_scores.threshold, df_scores['r'], label='R')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0011c0d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting contents of confusion matrix as different threasholds\n",
    "scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    \n",
    "    scores.append((t, tp, fp, fn, tn, p, r))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d493cbc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the scores into datafram\n",
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'p', 'r']\n",
    "df_scores = pd.DataFrame(scores, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "b5184f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>211</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>211</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.861224</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>211</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>211</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>211</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold   tp  fp  fn  tn         p    r\n",
       "0       0.00  211  53   0   0  0.799242  1.0\n",
       "1       0.01  211  34   0  19  0.861224  1.0\n",
       "2       0.02  211  31   0  22  0.871901  1.0\n",
       "3       0.03  211  24   0  29  0.897872  1.0\n",
       "4       0.04  211  22   0  31  0.905579  1.0"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "4681d24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce00e3ba30>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_scores.threshold, df_scores['p'], label='P')\n",
    "plt.plot(df_scores.threshold, df_scores['r'], label='R')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efccf77",
   "metadata": {},
   "source": [
    "Precision and Recall intersect at 0.3 threashold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e3c0e67",
   "metadata": {},
   "source": [
    "# Question 4\n",
    "\n",
    "Precision and recall are conflicting - when one grows, the other goes down. That's why they are often combined into the F1 score - a metrics that takes into account both\n",
    "\n",
    "This is the formula for computing F1:\n",
    "\n",
    "F1 = 2 * P * R / (P + R)\n",
    "\n",
    "Where P is precision and R is recall.\n",
    "\n",
    "Let's compute F1 for all thresholds from 0.0 to 1.0 with increment 0.01\n",
    "\n",
    "At which threshold F1 is maximal?\n",
    "\n",
    "- 0.1\n",
    "- 0.4\n",
    "- 0.6\n",
    "- 0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "e18a0e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting contents of confusion matrix as different threasholds\n",
    "F1_scores = []\n",
    "\n",
    "thresholds = np.linspace(0, 1, 101)\n",
    "\n",
    "for t in thresholds:\n",
    "    actual_positive = (y_val == 1)\n",
    "    actual_negative = (y_val == 0)\n",
    "    \n",
    "    predict_positive = (y_pred >= t)\n",
    "    predict_negative = (y_pred < t)\n",
    "\n",
    "    tp = (predict_positive & actual_positive).sum()\n",
    "    tn = (predict_negative & actual_negative).sum()\n",
    "\n",
    "    fp = (predict_positive & actual_negative).sum()\n",
    "    fn = (predict_negative & actual_positive).sum()\n",
    "    p = tp / (tp + fp)\n",
    "    r = tp / (tp + fn)\n",
    "    F1 = 2 * p * r / (p + r)\n",
    "    \n",
    "    F1_scores.append((t, tp, fp, fn, tn, p, r, F1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "260f90b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Putting the scores into datafram\n",
    "columns = ['threshold', 'tp', 'fp', 'fn', 'tn', 'p', 'r', 'F1']\n",
    "df_F1_scores = pd.DataFrame(F1_scores, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3d445d44",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>tp</th>\n",
       "      <th>fp</th>\n",
       "      <th>fn</th>\n",
       "      <th>tn</th>\n",
       "      <th>p</th>\n",
       "      <th>r</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>211</td>\n",
       "      <td>53</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.799242</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.888421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.01</td>\n",
       "      <td>211</td>\n",
       "      <td>34</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>0.861224</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925439</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.02</td>\n",
       "      <td>211</td>\n",
       "      <td>31</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>0.871901</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931567</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.03</td>\n",
       "      <td>211</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>29</td>\n",
       "      <td>0.897872</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.946188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.04</td>\n",
       "      <td>211</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.05</td>\n",
       "      <td>211</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>31</td>\n",
       "      <td>0.905579</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.950450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.06</td>\n",
       "      <td>211</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.07</td>\n",
       "      <td>211</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>0.917391</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.956916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.08</td>\n",
       "      <td>210</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.956720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.09</td>\n",
       "      <td>210</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>35</td>\n",
       "      <td>0.921053</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.956720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.10</td>\n",
       "      <td>210</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.11</td>\n",
       "      <td>210</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.12</td>\n",
       "      <td>210</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>36</td>\n",
       "      <td>0.925110</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.958904</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.13</td>\n",
       "      <td>210</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>0.950226</td>\n",
       "      <td>0.995261</td>\n",
       "      <td>0.972222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.14</td>\n",
       "      <td>208</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.15</td>\n",
       "      <td>208</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>44</td>\n",
       "      <td>0.958525</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.971963</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.16</td>\n",
       "      <td>208</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.976526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.17</td>\n",
       "      <td>208</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>46</td>\n",
       "      <td>0.967442</td>\n",
       "      <td>0.985782</td>\n",
       "      <td>0.976526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.18</td>\n",
       "      <td>207</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>47</td>\n",
       "      <td>0.971831</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.976415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.19</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.20</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.21</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.22</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.23</td>\n",
       "      <td>207</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976415</td>\n",
       "      <td>0.981043</td>\n",
       "      <td>0.978723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.24</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.25</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.26</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.27</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.28</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.29</td>\n",
       "      <td>206</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "      <td>0.976303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.30</td>\n",
       "      <td>205</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>48</td>\n",
       "      <td>0.976190</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.973872</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.31</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.32</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.33</td>\n",
       "      <td>205</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>0.980861</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.976190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.34</td>\n",
       "      <td>205</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>51</td>\n",
       "      <td>0.990338</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.980861</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.35</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.36</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.37</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.38</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.39</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.40</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0.41</td>\n",
       "      <td>205</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995146</td>\n",
       "      <td>0.971564</td>\n",
       "      <td>0.983213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>0.42</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>0.43</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>0.44</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>0.45</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>0.46</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>0.47</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0.48</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>0.49</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.50</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0.51</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>0.52</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>53</th>\n",
       "      <td>0.53</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>54</th>\n",
       "      <td>0.54</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>0.55</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.56</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>0.57</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>0.58</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>59</th>\n",
       "      <td>0.59</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>0.60</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>0.61</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0.62</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>0.63</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>0.64</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>0.65</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0.66</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>67</th>\n",
       "      <td>0.67</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>0.68</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>69</th>\n",
       "      <td>0.69</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>0.70</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>71</th>\n",
       "      <td>0.71</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0.72</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>0.73</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>74</th>\n",
       "      <td>0.74</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75</th>\n",
       "      <td>0.75</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>76</th>\n",
       "      <td>0.76</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>0.77</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.78</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>0.79</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>0.80</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>0.81</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>0.82</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.83</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0.84</td>\n",
       "      <td>204</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>52</td>\n",
       "      <td>0.995122</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.980769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0.85</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0.86</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0.87</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0.88</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0.89</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>0.90</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>0.91</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0.92</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>93</th>\n",
       "      <td>0.93</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>0.94</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>0.95</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>0.96</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.966825</td>\n",
       "      <td>0.983133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>0.97</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962085</td>\n",
       "      <td>0.980676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>0.98</td>\n",
       "      <td>203</td>\n",
       "      <td>0</td>\n",
       "      <td>8</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.962085</td>\n",
       "      <td>0.980676</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>0.99</td>\n",
       "      <td>202</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.957346</td>\n",
       "      <td>0.978208</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>1.00</td>\n",
       "      <td>179</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>53</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.848341</td>\n",
       "      <td>0.917949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     threshold   tp  fp  fn  tn         p         r        F1\n",
       "0         0.00  211  53   0   0  0.799242  1.000000  0.888421\n",
       "1         0.01  211  34   0  19  0.861224  1.000000  0.925439\n",
       "2         0.02  211  31   0  22  0.871901  1.000000  0.931567\n",
       "3         0.03  211  24   0  29  0.897872  1.000000  0.946188\n",
       "4         0.04  211  22   0  31  0.905579  1.000000  0.950450\n",
       "5         0.05  211  22   0  31  0.905579  1.000000  0.950450\n",
       "6         0.06  211  19   0  34  0.917391  1.000000  0.956916\n",
       "7         0.07  211  19   0  34  0.917391  1.000000  0.956916\n",
       "8         0.08  210  18   1  35  0.921053  0.995261  0.956720\n",
       "9         0.09  210  18   1  35  0.921053  0.995261  0.956720\n",
       "10        0.10  210  17   1  36  0.925110  0.995261  0.958904\n",
       "11        0.11  210  17   1  36  0.925110  0.995261  0.958904\n",
       "12        0.12  210  17   1  36  0.925110  0.995261  0.958904\n",
       "13        0.13  210  11   1  42  0.950226  0.995261  0.972222\n",
       "14        0.14  208   9   3  44  0.958525  0.985782  0.971963\n",
       "15        0.15  208   9   3  44  0.958525  0.985782  0.971963\n",
       "16        0.16  208   7   3  46  0.967442  0.985782  0.976526\n",
       "17        0.17  208   7   3  46  0.967442  0.985782  0.976526\n",
       "18        0.18  207   6   4  47  0.971831  0.981043  0.976415\n",
       "19        0.19  207   5   4  48  0.976415  0.981043  0.978723\n",
       "20        0.20  207   5   4  48  0.976415  0.981043  0.978723\n",
       "21        0.21  207   5   4  48  0.976415  0.981043  0.978723\n",
       "22        0.22  207   5   4  48  0.976415  0.981043  0.978723\n",
       "23        0.23  207   5   4  48  0.976415  0.981043  0.978723\n",
       "24        0.24  206   5   5  48  0.976303  0.976303  0.976303\n",
       "25        0.25  206   5   5  48  0.976303  0.976303  0.976303\n",
       "26        0.26  206   5   5  48  0.976303  0.976303  0.976303\n",
       "27        0.27  206   5   5  48  0.976303  0.976303  0.976303\n",
       "28        0.28  206   5   5  48  0.976303  0.976303  0.976303\n",
       "29        0.29  206   5   5  48  0.976303  0.976303  0.976303\n",
       "30        0.30  205   5   6  48  0.976190  0.971564  0.973872\n",
       "31        0.31  205   4   6  49  0.980861  0.971564  0.976190\n",
       "32        0.32  205   4   6  49  0.980861  0.971564  0.976190\n",
       "33        0.33  205   4   6  49  0.980861  0.971564  0.976190\n",
       "34        0.34  205   2   6  51  0.990338  0.971564  0.980861\n",
       "35        0.35  205   1   6  52  0.995146  0.971564  0.983213\n",
       "36        0.36  205   1   6  52  0.995146  0.971564  0.983213\n",
       "37        0.37  205   1   6  52  0.995146  0.971564  0.983213\n",
       "38        0.38  205   1   6  52  0.995146  0.971564  0.983213\n",
       "39        0.39  205   1   6  52  0.995146  0.971564  0.983213\n",
       "40        0.40  205   1   6  52  0.995146  0.971564  0.983213\n",
       "41        0.41  205   1   6  52  0.995146  0.971564  0.983213\n",
       "42        0.42  204   1   7  52  0.995122  0.966825  0.980769\n",
       "43        0.43  204   1   7  52  0.995122  0.966825  0.980769\n",
       "44        0.44  204   1   7  52  0.995122  0.966825  0.980769\n",
       "45        0.45  204   1   7  52  0.995122  0.966825  0.980769\n",
       "46        0.46  204   1   7  52  0.995122  0.966825  0.980769\n",
       "47        0.47  204   1   7  52  0.995122  0.966825  0.980769\n",
       "48        0.48  204   1   7  52  0.995122  0.966825  0.980769\n",
       "49        0.49  204   1   7  52  0.995122  0.966825  0.980769\n",
       "50        0.50  204   1   7  52  0.995122  0.966825  0.980769\n",
       "51        0.51  204   1   7  52  0.995122  0.966825  0.980769\n",
       "52        0.52  204   1   7  52  0.995122  0.966825  0.980769\n",
       "53        0.53  204   1   7  52  0.995122  0.966825  0.980769\n",
       "54        0.54  204   1   7  52  0.995122  0.966825  0.980769\n",
       "55        0.55  204   1   7  52  0.995122  0.966825  0.980769\n",
       "56        0.56  204   1   7  52  0.995122  0.966825  0.980769\n",
       "57        0.57  204   1   7  52  0.995122  0.966825  0.980769\n",
       "58        0.58  204   1   7  52  0.995122  0.966825  0.980769\n",
       "59        0.59  204   1   7  52  0.995122  0.966825  0.980769\n",
       "60        0.60  204   1   7  52  0.995122  0.966825  0.980769\n",
       "61        0.61  204   1   7  52  0.995122  0.966825  0.980769\n",
       "62        0.62  204   1   7  52  0.995122  0.966825  0.980769\n",
       "63        0.63  204   1   7  52  0.995122  0.966825  0.980769\n",
       "64        0.64  204   1   7  52  0.995122  0.966825  0.980769\n",
       "65        0.65  204   1   7  52  0.995122  0.966825  0.980769\n",
       "66        0.66  204   1   7  52  0.995122  0.966825  0.980769\n",
       "67        0.67  204   1   7  52  0.995122  0.966825  0.980769\n",
       "68        0.68  204   1   7  52  0.995122  0.966825  0.980769\n",
       "69        0.69  204   1   7  52  0.995122  0.966825  0.980769\n",
       "70        0.70  204   1   7  52  0.995122  0.966825  0.980769\n",
       "71        0.71  204   1   7  52  0.995122  0.966825  0.980769\n",
       "72        0.72  204   1   7  52  0.995122  0.966825  0.980769\n",
       "73        0.73  204   1   7  52  0.995122  0.966825  0.980769\n",
       "74        0.74  204   1   7  52  0.995122  0.966825  0.980769\n",
       "75        0.75  204   1   7  52  0.995122  0.966825  0.980769\n",
       "76        0.76  204   1   7  52  0.995122  0.966825  0.980769\n",
       "77        0.77  204   1   7  52  0.995122  0.966825  0.980769\n",
       "78        0.78  204   1   7  52  0.995122  0.966825  0.980769\n",
       "79        0.79  204   1   7  52  0.995122  0.966825  0.980769\n",
       "80        0.80  204   1   7  52  0.995122  0.966825  0.980769\n",
       "81        0.81  204   1   7  52  0.995122  0.966825  0.980769\n",
       "82        0.82  204   1   7  52  0.995122  0.966825  0.980769\n",
       "83        0.83  204   1   7  52  0.995122  0.966825  0.980769\n",
       "84        0.84  204   1   7  52  0.995122  0.966825  0.980769\n",
       "85        0.85  204   0   7  53  1.000000  0.966825  0.983133\n",
       "86        0.86  204   0   7  53  1.000000  0.966825  0.983133\n",
       "87        0.87  204   0   7  53  1.000000  0.966825  0.983133\n",
       "88        0.88  204   0   7  53  1.000000  0.966825  0.983133\n",
       "89        0.89  204   0   7  53  1.000000  0.966825  0.983133\n",
       "90        0.90  204   0   7  53  1.000000  0.966825  0.983133\n",
       "91        0.91  204   0   7  53  1.000000  0.966825  0.983133\n",
       "92        0.92  204   0   7  53  1.000000  0.966825  0.983133\n",
       "93        0.93  204   0   7  53  1.000000  0.966825  0.983133\n",
       "94        0.94  204   0   7  53  1.000000  0.966825  0.983133\n",
       "95        0.95  204   0   7  53  1.000000  0.966825  0.983133\n",
       "96        0.96  204   0   7  53  1.000000  0.966825  0.983133\n",
       "97        0.97  203   0   8  53  1.000000  0.962085  0.980676\n",
       "98        0.98  203   0   8  53  1.000000  0.962085  0.980676\n",
       "99        0.99  202   0   9  53  1.000000  0.957346  0.978208\n",
       "100       1.00  179   0  32  53  1.000000  0.848341  0.917949"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_F1_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "81a07fcc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7fce00f0de50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(df_F1_scores.threshold, df_F1_scores['p'], label='P')\n",
    "plt.plot(df_F1_scores.threshold, df_F1_scores['r'], label='R')\n",
    "plt.plot(df_F1_scores.threshold, df_F1_scores['F1'], label='F')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d5fccc1",
   "metadata": {},
   "source": [
    "F1 is at the maximum at 0.40"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a614681",
   "metadata": {},
   "source": [
    "# Question 5\n",
    "\n",
    "Use the KFold class from Scikit-Learn to evaluate our model on 5 different folds:\n",
    "\n",
    "KFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "- Iterate over different folds of df_full_train\n",
    "- Split the data into train and validation\n",
    "- Train the model on train with these parameters: LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "- Use AUC to evaluate the model on validation\n",
    "\n",
    "How large is standard devidation of the AUC scores across different folds?\n",
    "\n",
    "- 0.003\n",
    "- 0.014\n",
    "- 0.09\n",
    "- 0.24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "2d507920",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = KFold(n_splits=5, shuffle=True, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "df31380c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_idx, val_idx = next(kfold.split(df_full_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "0c422c9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# len(train_idx), len(val_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f100907a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_full_train_use = df_full_train[use_columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a94f766c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_train = df_full_train_use.iloc[train_idx]\n",
    "# df_val = df_full_train_use.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "c15eb9e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_train = df_full_train.card.iloc[train_idx]\n",
    "# y_val = df_full_train.card.iloc[val_idx]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4305ce72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train(df_train, y_train):\n",
    "    dicts = df_train.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ce6555d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(df, dv, model):\n",
    "    dicts = df.to_dict(orient='records')\n",
    "\n",
    "    X = dv.transform(dicts)\n",
    "    y_pred = model.predict_proba(X)[:, 1]\n",
    "\n",
    "    return y_pred\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c4330dd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a04138d13af9494fa0dc02a0898a1f7f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "scores = []\n",
    "\n",
    "for train_idx, val_idx in tqdm(kfold.split(df_full_train)):\n",
    "    df_full_train_use = df_full_train[use_columns]\n",
    "    df_train = df_full_train_use.iloc[train_idx]\n",
    "    df_val = df_full_train_use.iloc[val_idx]\n",
    "\n",
    "    y_train = df_full_train.card.iloc[train_idx]\n",
    "    y_val = df_full_train.card.iloc[val_idx]\n",
    "\n",
    "    dv, model = train(df_train, y_train)\n",
    "    y_pred = predict(df_val, dv, model)\n",
    "\n",
    "    auc = roc_auc_score(y_val, y_pred)\n",
    "    scores.append(auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "e28ca9e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9941860465116279,\n",
       " 0.9941176470588236,\n",
       " 0.9943346508563901,\n",
       " 0.9996107939802803,\n",
       " 1.0]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ac2729ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "print('%.3f +- %.3f' % (np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e037694",
   "metadata": {},
   "source": [
    "It is 0.003 large"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3b192c1",
   "metadata": {},
   "source": [
    "# Question 6\n",
    "\n",
    "Now let's use 5-Fold cross-validation to find the best parameter C\n",
    "\n",
    "Iterate over the following C values: [0.01, 0.1, 1, 10]\n",
    "Initialize KFold with the same parameters as previously\n",
    "Use these parametes for the model: LogisticRegression(solver='liblinear', C=C, max_iter=1000)\n",
    "Compute the mean score as well as the std (round the mean and std to 3 decimal digits)\n",
    "Which C leads to the best mean score?\n",
    "\n",
    "- 0.01\n",
    "- 0.1\n",
    "- 1\n",
    "- 10\n",
    "\n",
    "If you have ties, select the score with the lowest std. If you still have ties, select the smallest C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7d9492dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "\n",
    "def train(df_train, y_train, C=1.0):\n",
    "    dicts = df_train.to_dict(orient='records')\n",
    "\n",
    "    dv = DictVectorizer(sparse=False)\n",
    "    X_train = dv.fit_transform(dicts)\n",
    "\n",
    "    model = LogisticRegression(solver='liblinear', C=1.0, max_iter=1000)\n",
    "    model.fit(X_train, y_train)\n",
    "    \n",
    "    return dv, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "2e80fb0e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1cd895598fdb49dc97a406f83b74086a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd95f4e0c550444980091b300aece928",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.01 0.996 +- 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c214628b6cc48e9a8c4a61117e205f5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=0.1 0.996 +- 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59688406481b41fd8c73bace4b75e4a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=1 0.996 +- 0.003\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e42a2e8757514bdb9c94fbe31ea168b6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0it [00:00, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C=10 0.996 +- 0.003\n"
     ]
    }
   ],
   "source": [
    "# Tuning the parameter of our logistic model i.e. C\n",
    "n_splits = 5\n",
    "\n",
    "for C in tqdm([0.01, 0.1, 1, 10]):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=1)\n",
    "\n",
    "    scores = []\n",
    "\n",
    "    for train_idx, val_idx in tqdm(kfold.split(df_full_train)):\n",
    "        df_full_train_use = df_full_train[use_columns]\n",
    "        df_train = df_full_train_use.iloc[train_idx]\n",
    "        df_val = df_full_train_use.iloc[val_idx]\n",
    "\n",
    "        y_train = df_full_train.card.iloc[train_idx]\n",
    "        y_val = df_full_train.card.iloc[val_idx]\n",
    "\n",
    "        dv, model = train(df_train, y_train, C=C)\n",
    "        y_pred = predict(df_val, dv, model)\n",
    "\n",
    "        auc = roc_auc_score(y_val, y_pred)\n",
    "        scores.append(auc)\n",
    "    \n",
    "    print('C=%s %.3f +- %.3f' % (C, np.mean(scores), np.std(scores)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c34d570b",
   "metadata": {},
   "source": [
    "0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfacafa",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
